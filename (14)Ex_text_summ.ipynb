{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvhTC8GpGjB0UbK25Cic8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyasupriyakonda/NLP/blob/main/(14)Ex_text_summ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def extractive_summarization(document, num_sentences=3):\n",
        "    # Step 1: Sentence Tokenization\n",
        "    sentences = sent_tokenize(document)\n",
        "\n",
        "    # Step 2: Text Preprocessing\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word.lower() for sentence in sentences for word in nltk.word_tokenize(sentence) if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "    # Step 3: Calculate Sentence Scores\n",
        "    word_freq = FreqDist(words)\n",
        "    sentence_scores = {sentence: sum(word_freq[word] for word in nltk.word_tokenize(sentence) if word.isalnum() and word.lower() not in stop_words) for sentence in sentences}\n",
        "\n",
        "    # Step 4: Select Top Sentences\n",
        "    top_sentences = sorted(sentences, key=lambda sentence: sentence_scores[sentence], reverse=True)[:num_sentences]\n",
        "\n",
        "    # Detokenize to form the final summary\n",
        "    summary = TreebankWordDetokenizer().detokenize(top_sentences)\n",
        "\n",
        "    return summary\n",
        "\n",
        "document = \"\"\"\n",
        "Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. NLP technologies are used to process, analyze, and understand large amounts of natural language data.\n",
        "\n",
        "One of the primary applications of NLP is sentiment analysis, which determines the sentiment or emotional tone of a piece of text. Sentiment analysis is widely used in social media monitoring, customer feedback analysis, and brand reputation management.\n",
        "\n",
        "Text summarization is another important NLP task. Extractive summarization involves selecting a subset of sentences from a text to create a shorter version that retains the most critical information. Abstractive summarization, on the other hand, generates a summary by paraphrasing and rephrasing the original text. The extractive summarization method typically involves the following steps:\n",
        "\n",
        "1. Sentence Tokenization: Divide the text into individual sentences.\n",
        "\n",
        "2. Text Preprocessing: Remove stopwords and punctuation, and convert words to lowercase.\n",
        "\n",
        "3. Calculate Sentence Scores: Assign scores to sentences based on their importance.\n",
        "\n",
        "4. Select Top Sentences: Choose sentences with the highest scores to form the summary.\n",
        "\"\"\"\n",
        "\n",
        "# Set the number of sentences you want in the summary (default is 3)\n",
        "num_sentences_in_summary = 3\n",
        "\n",
        "result_summary = extractive_summarization(document, num_sentences=num_sentences_in_summary)\n",
        "print(result_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkMn1bCUL8x2",
        "outputId": "7324ec29-50bc-4f4a-9130-5ea107179add"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extractive summarization involves selecting a subset of sentences from a text to create a shorter version that retains the most critical information. One of the primary applications of NLP is sentiment analysis, which determines the sentiment or emotional tone of a piece of text. \n",
            "Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}